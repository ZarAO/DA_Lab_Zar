{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Formatted Date              0\n",
       "Summary                     0\n",
       "Precip Type                 0\n",
       "Temperature (C)             0\n",
       "Apparent Temperature (C)    0\n",
       "Humidity                    0\n",
       "Wind Speed (km/h)           0\n",
       "Wind Bearing (degrees)      0\n",
       "Visibility (km)             0\n",
       "Pressure (millibars)        0\n",
       "Daily Summary               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "df = pd.read_csv('weatherHistory_v1.csv')\n",
    "df = df.drop('Loud Cover',axis=1)\n",
    "df = df.replace('?', np.NaN)\n",
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Formatted Date'] = pd.Categorical(df['Formatted Date'])\n",
    "df['Summary'] = pd.Categorical(df['Summary'])\n",
    "df['Precip Type'] = pd.Categorical(df['Precip Type'])\n",
    "df['Daily Summary'] = pd.Categorical(df['Daily Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include='category').columns:\n",
    "    if column=='Precip Type':\n",
    "        continue\n",
    "    df = pd.concat([df, pd.get_dummies(df[column], prefix=column)],axis=1)\n",
    "    df.drop([column],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Precip Type',axis=1), df['Precip Type'].cat.codes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include='float64').columns:\n",
    "    scale = StandardScaler().fit(X_train[[column]])\n",
    "    X_train[[column]] = scale.transform(X_train[[column]])\n",
    "    X_test[[column]] = scale.transform(X_test[[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=31811, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "792/792 [==============================] - 6s 7ms/step - loss: -1460.5919 - accuracy: 1.2301e-04\n",
      "Epoch 2/10\n",
      "792/792 [==============================] - 5s 7ms/step - loss: -46317.0846 - accuracy: 1.1768e-04\n",
      "Epoch 3/10\n",
      "792/792 [==============================] - 6s 7ms/step - loss: -224165.4698 - accuracy: 2.0036e-04\n",
      "Epoch 4/10\n",
      "792/792 [==============================] - 5s 7ms/step - loss: -585342.6899 - accuracy: 1.8293e-04\n",
      "Epoch 5/10\n",
      "792/792 [==============================] - 5s 7ms/step - loss: -1155753.0697 - accuracy: 5.9302e-05\n",
      "Epoch 6/10\n",
      "792/792 [==============================] - 5s 7ms/step - loss: -1956464.0709 - accuracy: 2.8684e-04\n",
      "Epoch 7/10\n",
      "792/792 [==============================] - 5s 7ms/step - loss: -2983989.7478 - accuracy: 1.4160e-04\n",
      "Epoch 8/10\n",
      "792/792 [==============================] - 5s 7ms/step - loss: -4294454.5782 - accuracy: 1.1467e-04\n",
      "Epoch 9/10\n",
      "792/792 [==============================] - 5s 7ms/step - loss: -5879854.2673 - accuracy: 1.9243e-04\n",
      "Epoch 10/10\n",
      "792/792 [==============================] - 6s 7ms/step - loss: -7788027.6803 - accuracy: 9.5103e-05\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x248d702f390>"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.00047355958958168905"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.00      1.00      0.00         3\n           2       0.00      0.00      0.00        25\n           3       0.00      0.00      0.00        32\n           4       0.00      0.00      0.00        35\n           5       0.00      0.00      0.00       895\n           7       0.00      0.00      0.00         5\n           8       0.00      0.00      0.00         6\n           9       0.00      0.00      0.00       427\n          10       0.00      0.00      0.00         2\n          11       0.00      0.00      0.00         2\n          12       0.00      0.00      0.00      1690\n          13       0.00      0.00      0.00      1032\n          14       0.00      0.00      0.00      2168\n          15       0.00      0.00      0.00         1\n          17       0.00      0.00      0.00         2\n          18       0.00      0.00      0.00         3\n          19       0.00      0.00      0.00         6\n\n    accuracy                           0.00      6335\n   macro avg       0.00      0.06      0.00      6335\nweighted avg       0.00      0.00      0.00      6335\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    3    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0   25    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0   32    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0   35    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0  895    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    5    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    6    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0  427    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    2    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    2    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0 1690    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0 1032    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0 2168    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    2    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    3    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    6    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN lost to AdaBoost and GBoost but outperformed all other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN - in file 2_CNN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, GlobalMaxPooling1D, SimpleRNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   class                                      response_text\n",
       "0      0              I try and avoid this sort of conflict\n",
       "1      1  Had a friend open up to me about his mental ad...\n",
       "2      2                                                  2\n",
       "3      0  i cant think of one really...i think i may hav...\n",
       "4      2                                                  2\n",
       "5      0  a couple of years ago my friends was going to ...\n",
       "6      1  Roommate when he was going through death and l...\n",
       "7      1  i've had a couple of friends (you could say mo...\n",
       "8      0  Listened to someone talk about relationship tr...\n",
       "9      2                                                  2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>response_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>I try and avoid this sort of conflict</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Had a friend open up to me about his mental ad...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>i cant think of one really...i think i may hav...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>a couple of years ago my friends was going to ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>Roommate when he was going through death and l...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>i've had a couple of friends (you could say mo...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>Listened to someone talk about relationship tr...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "data = pd.read_csv('Sheet.csv')\n",
    "data = data.drop('response_id',axis=1)\n",
    "data = data.replace('not_flagged', 0)\n",
    "data = data.replace('flagged', 1)\n",
    "data = data.replace(np.NaN, '2')\n",
    "data = data.astype({'class': 'int64'})\n",
    "#data.dtypes\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(64,) (16,)\n"
     ]
    }
   ],
   "source": [
    "text = data['response_text'].values\n",
    "labels = data['class'].values\n",
    "text_train, text_test, y_train, y_test = train_test_split(text, labels, test_size=0.2, random_state=42)\n",
    "print(text_train.shape, text_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "data.response_text.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "maxlen = 135\n",
    "embedding_size = 32\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(text_train)\n",
    "x_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, 135, 32)           160000    \n_________________________________________________________________\nsimple_rnn_3 (SimpleRNN)     (None, 135, 32)           2080      \n_________________________________________________________________\nglobal_max_pooling1d_3 (Glob (None, 32)                0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_33 (Dense)             (None, 1)                 33        \n=================================================================\nTotal params: 162,113\nTrainable params: 162,113\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=maxlen))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.5725 - accuracy: 0.2188 - val_loss: 0.6220 - val_accuracy: 0.0625\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5263 - accuracy: 0.2188 - val_loss: 0.6130 - val_accuracy: 0.0625\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5154 - accuracy: 0.2031 - val_loss: 0.6087 - val_accuracy: 0.0625\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4682 - accuracy: 0.2031 - val_loss: 0.6074 - val_accuracy: 0.0625\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4637 - accuracy: 0.2188 - val_loss: 0.6056 - val_accuracy: 0.0625\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=512, validation_data=(x_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 6.25%\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test)>0.5\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}